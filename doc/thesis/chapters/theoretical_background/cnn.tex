\section{Convolutional Neural Network}
\label{sec:theoretical_background:cnn}

\Acrlongpl{cnn} feature a specialized architecture to process data that has a known grid-like topology, such as images.
They are based on \acrlongpl{ann} and the mathematical convolution operation \cite[p.~326--331]{deeplearningbook}.

The main problems when working with color images is that they are high-dimensional and therefore require a lot of processing power.
For this reason, \acrlongpl{cnn} use special layers to detect features and reduce the amount of data.

% ------------------------------------------------------------------------------------------------------------------------------
\subsection{Architecture}
\label{subsec:theoretical_background:cnn:architecture}

A \acrlong{cnn} features a variety of different layers.
The three most relevant layers are described in this section.

% -----------------------------
\paragraph{Convolutional Layer}
Convolutional layers apply a set amount of filters to the input image.
Filters are used to recognize certain features (e.g. edges) and consist of as many so-called kernels as there are input channels.
A kernel is applied by sliding it along an input channel and calculating the scalar product of the overlapping region.
This generates new layers which are summed up to a feature maps. % feature map
The first convolutional layers are responsible for detecting low-level features, while following layers are responsible for detecting high-level features \cite[p.~327--330]{deeplearningbook}.

Convolutional layers require the specification of many hyperparameters:
\begin{enumerate}
  \item Number of filters
  \item Kernel size
  \item Padding
  \item Stride
  \item Activation
  \item Bias
\end{enumerate}

The number of filters corresponds to the number of convolved feature maps produced.
The kernel size specifies the height and the width of the convolution window used.
Padding can be used to preserve the spatial dimensions by adding layers of zeros to the input image.
Stride specifies the amount of movement between applications of the filter.
The activation parameter is used to specify an activation function (typically \acrshort{relu}).
Finally, the bias parameter specifies whether to use a bias term.

% -----------------------
\paragraph{Pooling Layer}
Pooling layers are used to reduce the spatial dimensions of the convolved feature maps.
This is done by replacing a rectangular region of the feature map with a summary of this region.
Maximum pooling yields the maximum value and average pooling yields the average value of a specific rectangular region.
Usually, max-pooling is used to preserve large values which correspond to detected features.
By doing so, the required computational power is significantly decreased and the dominant features are extracted \cite[p.~335--339]{deeplearningbook}.

Max-pooling layers mainly require two hyperparameters: the pool size and the strides value.
The pool size is the region over which the maximum is taken.
The strides value specifies how far the pooling window moves for each pooling step.

% -------------------------------
\paragraph{Fully-Connected Layer}
If every artificial neuron in layer $n$ is connected to every artificial neuron in layer $n + 1$, it is referred to as a fully-connected or dense layer.
Fully-connected layers are responsible for learning the non-linear combinations of the high-level convolved feature maps.
They are used at the end of \acrshortpl{cnn} to flatten the result of the convolution process into a vector of values.
The output layer usually contains as many artificial neurons as there are classes \cite{cnn_fc}.

The three main hyperparameters of fully-connected layers are the number of artificial neurons, the activation function and wheter to use a bias term.
