\section{Training}
\label{sec:training_of_the_cnn:training}

The actual training of the \acrlong{cnn} model is implemented in the Python script \texttt{cnn.py} and uses the high-level Keras \acrshort{api} from the \texttt{tf.keras} module \cite{training_arch_tf_keras}.
Four main steps are required to train the model:

\begin{enumerate}
  \item Defining the architecture (as shown in section \ref{subsec:training_of_the_cnn:architecture:implementation})
  \item Loading the training and validation datasets
  \item Compiling the model
  \item Fitting the model
\end{enumerate}

The first step is the definition of the \acrshort{cnn} architecture explained in section \ref{subsec:training_of_the_cnn:architecture:implementation}.

The second step is to load the training and validation datasets.
Since there are so many frames in the datasets, the frames are loaded in batches of \num{32} (see section \ref{subsec:training_of_the_cnn:dataset:splitting}).
The pixel values of the frames are then converted to a 32-bit floating-point format, which is necessary for the training and further increases the required memory by a factor of \num{4}.
To avoid unexpected behaviour during training, the pixel values have to be normalized to the range between \numrange{0}{1} \cite{training_train_scaling}.

This is done with the help of the \texttt{Dataset\_Generator} class.
The \texttt{Dataset\_Generator} class inherits from the \texttt{tf.keras.utils.Sequence} superclass.
The constructor loads the entire labels NumPy array and intializes the attributes of the class.
Every \texttt{tf.keras.utils.Sequence} must implement the \texttt{\_\_len\_\_} and \texttt{\_\_getitem\_\_} methods \cite{training_arch_tf_keras_sequence}.
The \texttt{\_\_len\_\_} method returns the total number of batches when the build-in Python \texttt{len} function is called.
The \texttt{\_\_getitem\_\_} method loads a batch of frames as a NumPy array, converts the datatype to \texttt{np.float32} and normalizes the pixel values to the range between \numrange{0}{1}.
The normalization is done by dividing all pixel values by the largest possible pixel value of \num{255}.
After the normalization, the labels array is split accordingly and the batch of normalized frames and labels is return as a tuple.
The \texttt{\_\_getitem\_\_} method is invoked when the indexing operator \texttt{[]} is used on an object.
The definition of the \texttt{Dataset\_Generator} class is shown in listing \ref{lst:dataset_generator_class} and the instantiation of the dataset objects is shown in listing \ref{lst:model_fitting} on line \ref{lst:ln:training_dataset} and \ref{lst:ln:validation_dataset}.

\begin{lstlisting}[style=python, caption={\texttt{Dataset\_Generator} class}, label=lst:dataset_generator_class]
class Dataset_Generator(utils.Sequence):
  def __init__(self, frames_name, labels_name, directory, num_batches,
               batch_size):
    self.frames_name = frames_name
    self.labels = np.load(directory / f'{labels_name}.npy')
    self.directory = directory
    self.num_batches = num_batches
    self.batch_size = batch_size

  def __len__(self):
    return self.num_batches

  def __getitem__(self, idx):
    start = idx * self.batch_size
    end = start + self.batch_size

    name = f'{self.frames_name}_batch_{idx}_of_{self.num_batches}.npy'
    frames = np.load(self.directory / name)

    batch_x = frames.astype(np.float32) / 255.0
    batch_y = np.asarray(self.labels[start:end])

    return batch_x, batch_y
\end{lstlisting}

\begin{lstlisting}[style=python, caption={Training of the model}, label=lst:model_fitting]
# 2. Loading the datasets
training_dataset = fh.Dataset_Generator((*\label{lst:ln:training_dataset}*)
  fh.training_frames_name, fh.training_labels_name,
  fh.dir_training_dataset, 4903, 32)
validation_dataset = fh.Dataset_Generator((*\label{lst:ln:validation_dataset}*)
  fh.validation_frames_name, fh.validation_labels_name,
  fh.dir_validation_dataset, 1050, 32)

# 3. Compile the model
model.compile((*\label{lst:ln:compile}*)
  optimizer='adam',
  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])

# Save only the weights after each epoch
cp_callback = tf.keras.callbacks.ModelCheckpoint(
  filepath=str(fh.dir_checkpoint / 'cp-{epoch:04d}.ckpt'),
  save_weights_only=True,
  verbose=1,
  save_freq='epoch')

# 4. Fit the model
history = model.fit((*\label{lst:ln:fit}*)
  x=training_dataset,
  epochs=10,
  validation_data=validation_dataset,
  callbacks=[cp_callback])
\end{lstlisting}

In a third step, the \acrshort{cnn} model is compiled, which configures it for training \cite{training_arch_tf_keras_sequential}.
For this reason, an optimizer, a loss function and desired metrics to evaluate are specified.
The \textit{Adam} optimizer is used, as it is computationally efficient and can handle a large number of parameters \cite{training_arch_adam}.
The cross-entropy loss function is used to evaluate how well the data is modeled.
Therefore, it calculates the cross-entropy between the probability distribution of the predictions and the true labels \cite{training_train_entropy}.
Keras provides the required implementation with the \texttt{SparseCategoricalCrossentropy} class.
The \textit{Sparse} indicates that the labels must be provided as integers rather than in a one-hot representation.
Additionally, the \textit{Categorical} indicates that it is a multiclass classification problem and not a binary one \cite{training_train_tf_keras_crossentropy}.
The method call is shown in listing \ref{lst:model_fitting} on line \ref{lst:ln:compile}.

The last step is the fitting of the model, which is done in so-called epochs.
During an epoch, the entire dataset is used to train the model.
The training is performed batch-wise, which means that the weights are only updated after considering an entire batch \cite{training_arch_tf_keras_sequential}.
The implementation saves the weights after each of the ten epochs (see listing \ref{lst:model_fitting} on line \ref{lst:ln:fit}).

The training of the \acrshort{cnn} model is performed on a decent laptop computer featuring an Intel Core i7-8850H processor with a max. turbo frequency of \SI{4.30}{GHz}, a mobile NVIDIA Quadro P3200 graphics card with \SI{6}{GiB} of dedicated \acrshort{gpu} memory and \SI{48}{GiB} of \acrshort{ram}.
The NVIDIA Quadro P3200 \acrshort{gpu} is CUDA-enabled and features a compute capability of \num{6.1} (which currently ranges from \numrange{2.0}{8.0}).
As a result, the CUDA toolkit allows the training process to take advantage of \acrshort{gpu} acceleration \cite{training_train_nvidia}.

The training of a single epoch takes about \SI{76}{min} on the \acrshort{cpu} and about \SI{6}{\min} on the \acrshort{gpu}.
This is a speedup of over $12\times$ when using the graphics card compared to the processor.

\subsection{Training Results}
\label{subsec:training_of_the_cnn:training:training_results}
Figure \ref{fig:training_results} shows the classification accuracy of the training and the validation dataset after each of the ten epochs.
It is evident that the accuracy converges extremely fast, which is probably due to the ideal conditions (e.g. consistent background, good lighting).
For this reason, no hyperparameter changes (e.g. number of epochs, batch size) are required.

The final classification accuracy is \num{0.993} for the training split and \num{0.996} for the validation split.
This shows that there is no overfitting and that the \acrshort{cnn} model generalized well.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{training_results}
  \caption{Results of the training of the \acrshort{cnn} model}
  \label{fig:training_results}
\end{figure}

\subsection{Saving of the Model}
\label{subsec:training_of_the_cnn:training:saving_of_the_model}
The final model fit is saved in the TensorFlow SavedModel file format (\texttt{assets/}, \texttt{variables/}, \texttt{saved\_model.pb}), which includes the weights and the computation (e.g. architecture, optimizer state).
This is very useful for sharing and deploying of the \acrshort{cnn} model \cite{training_train_tf_keras_saving_loading}.

Inference tasks commonly use the frozen graph file format (single \texttt{.pb} file), which contains the architecture and the weights.
Xilinx requires such a frozen graph for the quantization of the \acrshort{cnn} model.
Unfortunately, TensorFlow dropped support for freezing models since v2.x.
It is, however, still possible to freeze a model created with TensorFlow 2 with the usage of low-level TensorFlow \acrshort{api} calls.
Listing \ref{lst:frozen_graph} shows how the \texttt{frozen\_graph.pb} file is created \cite{training_train_frozen}.

For inference tasks, it is important to know the names of the input and output layers of the frozen graph.
How this information can be obtained is shown in listing \ref{lst:frozen_graph} on line \ref{lst:ln:input_info} and \ref{lst:ln:output_info}.
The name of the input layer is \texttt{x} and the name of the output layer is \texttt{Identity}.

\clearpage

\begin{lstlisting}[style=python, caption={Saving the model in the frozen graph file format \cite{training_train_frozen}}, label=lst:frozen_graph]
# Saving the frozen graph
# Convert the Keras model to a concrete function
full_model = tf.function(lambda x: model(x))
full_model = full_model.get_concrete_function(
  x=tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))

# Get the frozen concrete function
frozen_func = convert_variables_to_constants_v2(full_model)
frozen_func.graph.as_graph_def()

# Display information about the input and output layers
print(f'Input: {frozen_func.inputs}')(*\label{lst:ln:input_info}*)
print(f'Output: {frozen_func.outputs}')(*\label{lst:ln:output_info}*)

# Save the frozen graph from the frozen concrete function
tf.io.write_graph(
  graph_or_graph_def=frozen_func.graph,
  logdir=str(fh.dir_frozen_model),
  name='frozen_graph.pb',
  as_text=False)
\end{lstlisting}
